"""
Module x·ª≠ l√Ω ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu cho d·ª± √°n Customer Churn
√Åp d·ª•ng theo CRISP-DM Phase 3: Data Preparation
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split


def load_data(filepath):
    """
    T·∫£i d·ªØ li·ªáu t·ª´ file CSV
    
    Args:
        filepath (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file d·ªØ li·ªáu
        
    Returns:
        pd.DataFrame: DataFrame ch·ª©a d·ªØ li·ªáu
    """
    df = pd.read_csv(filepath)
    print(f"ƒê√£ t·∫£i d·ªØ li·ªáu: {df.shape[0]} h√†ng, {df.shape[1]} c·ªôt")
    return df


def handle_missing_values(df):
    """
    X·ª≠ l√Ω gi√° tr·ªã thi·∫øu trong d·ªØ li·ªáu
    
    Args:
        df (pd.DataFrame): DataFrame ƒë·∫ßu v√†o
        
    Returns:
        pd.DataFrame: DataFrame ƒë√£ x·ª≠ l√Ω gi√° tr·ªã thi·∫øu
    """
    # Chuy·ªÉn TotalCharges v·ªÅ s·ªë (c√≥ th·ªÉ c√≥ kho·∫£ng tr·∫Øng)
    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    
    # ƒêi·ªÅn gi√° tr·ªã thi·∫øu b·∫±ng median
    df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)
    
    print(f"S·ªë gi√° tr·ªã thi·∫øu sau x·ª≠ l√Ω: {df.isnull().sum().sum()}")
    return df


def encode_categorical_features(df):
    """
    M√£ h√≥a c√°c ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i
    
    Args:
        df (pd.DataFrame): DataFrame ƒë·∫ßu v√†o
        
    Returns:
        pd.DataFrame: DataFrame ƒë√£ m√£ h√≥a
    """
    # X√≥a c·ªôt customerID (kh√¥ng c·∫ßn thi·∫øt)
    if 'customerID' in df.columns:
        df = df.drop('customerID', axis=1)
    
    # M√£ h√≥a bi·∫øn ƒë√≠ch (Churn)
    df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})
    
    # One-Hot Encoding cho c√°c ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i kh√°c
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
    
    print(f"S·ªë ƒë·∫∑c tr∆∞ng sau m√£ h√≥a: {df.shape[1]}")
    return df


def split_features_target(df):
    """
    T√°ch ƒë·∫∑c tr∆∞ng v√† bi·∫øn ƒë√≠ch
    
    Args:
        df (pd.DataFrame): DataFrame ƒë·∫ßy ƒë·ªß
        
    Returns:
        tuple: (X, y) - ƒë·∫∑c tr∆∞ng v√† bi·∫øn ƒë√≠ch
    """
    X = df.drop('Churn', axis=1)
    y = df['Churn']
    
    print(f"Shape c·ªßa X: {X.shape}")
    print(f"Shape c·ªßa y: {y.shape}")
    print(f"T·ª∑ l·ªá Churn: {y.mean():.2%}")
    
    return X, y


def scale_features(X_train, X_test):
    """
    Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng s·ªë
    
    Args:
        X_train (pd.DataFrame): T·∫≠p hu·∫•n luy·ªán
        X_test (pd.DataFrame): T·∫≠p ki·ªÉm tra
        
    Returns:
        tuple: (X_train_scaled, X_test_scaled, scaler)
    """
    scaler = StandardScaler()
    
    # Ch·ªâ chu·∫©n h√≥a c√°c c·ªôt s·ªë
    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
    
    X_train_scaled = X_train.copy()
    X_test_scaled = X_test.copy()
    
    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])
    
    return X_train_scaled, X_test_scaled, scaler


def preprocess_pipeline(filepath, test_size=0.2, random_state=42):
    """
    Pipeline ƒë·∫ßy ƒë·ªß cho ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
    
    Args:
        filepath (str): ƒê∆∞·ªùng d·∫´n file d·ªØ li·ªáu
        test_size (float): T·ª∑ l·ªá t·∫≠p test
        random_state (int): Random seed
        
    Returns:
        tuple: (X_train, X_test, y_train, y_test, scaler)
    """
    print("=== B·∫ÆT ƒê·∫¶U TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU ===\n")
    
    # B∆∞·ªõc 1: T·∫£i d·ªØ li·ªáu
    df = load_data(filepath)
    
    # B∆∞·ªõc 2: X·ª≠ l√Ω gi√° tr·ªã thi·∫øu
    df = handle_missing_values(df)
    
    # B∆∞·ªõc 3: M√£ h√≥a ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i
    df = encode_categorical_features(df)
    
    # B∆∞·ªõc 4: T√°ch X v√† y
    X, y = split_features_target(df)
    
    # B∆∞·ªõc 5: Chia train-test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    print(f"\nƒê√£ chia d·ªØ li·ªáu: Train={len(X_train)}, Test={len(X_test)}")
    
    # B∆∞·ªõc 6: Chu·∫©n h√≥a
    X_train, X_test, scaler = scale_features(X_train, X_test)
    
    print("\n=== HO√ÄN T·∫§T TI·ªÄN X·ª¨ L√ù ===")
    
    return X_train, X_test, y_train, y_test, scaler


if __name__ == "__main__":
    # Test module
    filepath = "../WA_Fn-UseC_-Telco-Customer-Churn.csv"
    X_train, X_test, y_train, y_test, scaler = preprocess_pipeline(filepath)
    
    print("\nüìä T√≥m t·∫Øt d·ªØ li·ªáu:")
    print(f"- T·∫≠p train: {X_train.shape}")
    print(f"- T·∫≠p test: {X_test.shape}")
    print(f"- S·ªë ƒë·∫∑c tr∆∞ng: {X_train.shape[1]}")
